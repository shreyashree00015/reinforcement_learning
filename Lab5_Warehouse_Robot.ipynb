{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPeSwK2bYqPUqOWM1wAYuEP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VPTd6NIg5mYQ","executionInfo":{"status":"ok","timestamp":1715141396656,"user_tz":-330,"elapsed":388,"user":{"displayName":"Shreya Shree S","userId":"02564406637729607169"}},"outputId":"d0ca7637-e747-4ab7-a363-2778934103e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["[-100. -100. -100. -100. -100.  100. -100. -100. -100. -100. -100. -100.]\n","[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100. -100.]\n","[-100.   -1. -100. -100. -100. -100. -100.   -1. -100.   -1. -100. -100.]\n","[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.   -1. -100. -100.]\n","[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100. -100.]\n","[  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n","[-100. -100. -100. -100. -100.   -1. -100. -100. -100. -100. -100. -100.]\n","[-100.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100. -100.]\n","[-100. -100. -100.   -1. -100. -100. -100.   -1. -100. -100. -100. -100.]\n","[  -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1.   -1. -100.]\n","[-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]\n","[-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.]\n","Training complete!\n","[[[   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [ -99.           62.171        -3.19436236  -99.        ]\n","  [ -90.           70.19        -90.           54.37430269]\n","  [ -99.9999       79.1         -99.99         -1.7019    ]\n","  [ -99.9          89.          -90.           69.4881    ]\n","  [ 100.           79.1         -99.999        79.1       ]\n","  [-100.           70.19       -100.           89.        ]\n","  [-100.           62.171        62.171        79.1       ]\n","  [ -99.           48.56617896  -90.           70.19      ]\n","  [ -90.          -99.           -1.719        62.171     ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [  54.95389952  -99.99         21.70201004  -90.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [  70.19       -100.           54.95389994 -100.        ]\n","  [   0.            0.            0.            0.        ]\n","  [  54.9539      -99.           -2.38239     -99.999     ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [  -3.74449049   28.35462841  -90.          -90.        ]\n","  [ -90.           32.61625379  -99.9          -3.74870064]\n","  [ -99.99         37.3513931    28.35420894   25.25804938]\n","  [ -99.9999       42.612659    -99.9999       32.26538526]\n","  [ -99.99999      48.45851     -99.9          36.96078727]\n","  [ -99.9999       54.9539      -99.99         42.61202705]\n","  [  62.171      -100.           48.45851      48.45851   ]\n","  [   0.            0.            0.            0.        ]\n","  [  48.45851     -90.          -99.          -99.9       ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [  32.61625379  -99.999        24.49029362  -99.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [  54.9539      -99.99999999   42.612659   -100.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[ -99.99         17.96052411  -99.           15.14358642]\n","  [ -90.           21.06724901  -99.9          14.95990847]\n","  [ -99.9          24.51916557  -99.9          15.63970925]\n","  [  28.35462841   -4.53990346  -99.99         20.80818185]\n","  [ -99.99         32.61625379  -90.           24.23452204]\n","  [-100.           37.3513931    28.35141388   28.35462841]\n","  [ -99.9999999    42.612659    -99.9999999    32.61625379]\n","  [  48.45851      37.3513931  -100.           37.3513931 ]\n","  [ -90.           31.90106221  -99.9999       42.612659  ]\n","  [ -99.           25.07957284  -90.           37.3513931 ]\n","  [ -90.          -90.          -90.           32.61625379]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [  32.61625379  -99.99         24.51886882  -99.99999   ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [ -99.9          15.1644717   -99.          -99.        ]\n","  [ -99.           17.96052411  -90.           10.78995832]\n","  [-100.           21.06724901   13.12654667   13.10644279]\n","  [ -99.99         24.51916557  -99.99         17.72827461]\n","  [  28.35462841   21.06724899  -99.999        21.06724901]\n","  [ -99.99         17.96029162  -99.999        24.51916557]\n","  [ -99.99         10.73880522   14.95767586   21.06724901]\n","  [ -99.           -6.18133608  -90.           17.96052411]\n","  [ -99.          -90.          -99.           15.16446959]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [  17.96052411  -99.999        12.46219771  -99.99      ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [  17.96052411  -99.99         10.79956763  -99.999999  ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[ -99.9           8.34489987  -99.999        -6.45631333]\n","  [ -99.9          10.38322208  -90.           -6.08856531]\n","  [ -90.           12.64802453  -99.           -5.93187867]\n","  [  15.1644717    10.36659227  -99.99         10.21992436]\n","  [ -99.           -6.55568971  -99.           12.64802453]\n","  [ -99.9          -6.45688579  -99.9          10.38322208]\n","  [ -90.           12.64802453  -90.            5.70763431]\n","  [  15.1644717    -6.58311734  -99.99999      -6.11938626]\n","  [ -99.9           8.1948829   -99.99         12.64802453]\n","  [ -90.           -7.04061098  -99.9          10.38322208]\n","  [ -90.          -90.          -90.            8.34489982]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]\n","\n"," [[   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]\n","  [   0.            0.            0.            0.        ]]]\n","[]\n"]}],"source":["#!/usr/bin/python\n","\n","import numpy as np\n","\n","#define the shape of the environment (i.e., its states)\n","environment_rows = 12\n","environment_columns = 12\n","\n","#Create a 3D numpy array to hold the current Q-values for each state and action pair: Q(s, a)\n","#The array contains 11 rows and 11 columns (to match the shape of the environment), as well as a third \"action\" dimension.\n","#The \"action\" dimension consists of 4 layers that will allow us to keep track of the Q-values for each possible action in\n","#each state (see next cell for a description of possible actions).\n","#The value of each (state, action) pair is initialized to 0.\n","q_values = np.zeros((environment_rows, environment_columns, 4))\n","\n","#define actions\n","#numeric action codes: 0 = up, 1 = right, 2 = down, 3 = left\n","actions = ['up', 'right', 'down', 'left']\n","\n","#Create a 2D numpy array to hold the rewards for each state.\n","#The array contains 11 rows and 11 columns (to match the shape of the environment), and each value is initialized to -100.\n","rewards = np.full((environment_rows, environment_columns), -100.)\n","rewards[0, 5] = 100. #set the reward for the packaging area (i.e., the goal) to 100\n","\n","#define aisle locations (i.e., white squares) for rows 1 through 9\n","aisles = {} #store locations in a dictionary\n","aisles[1] = [i for i in range(1, 10)]\n","aisles[2] = [1, 7, 9]\n","aisles[3] = [i for i in range(1, 8)]\n","aisles[3].append(9)\n","aisles[4] = [3, 7]\n","aisles[5] = [i for i in range(11)]\n","aisles[6] = [5]\n","aisles[7] = [i for i in range(1, 10)]\n","aisles[8] = [3, 7]\n","aisles[9] = [i for i in range(11)]\n","\n","\n","#set the rewards for all aisle locations (i.e., white squares)\n","for row_index in range(1, 10):\n","  for column_index in aisles[row_index]:\n","    rewards[row_index, column_index] = -1.\n","\n","#print rewards matrix\n","for row in rewards:\n","  print(row)\n","\n","#define a function that determines if the specified location is a terminal state\n","def is_terminal_state(current_row_index, current_column_index):\n","  #if the reward for this location is -1, then it is not a terminal state (i.e., it is a 'white square')\n","  if rewards[current_row_index, current_column_index] == -1.:\n","    return False\n","  else:\n","    return True\n","\n","#define a function that will choose a random, non-terminal starting location\n","def get_starting_location():\n","  #get a random row and column index\n","  current_row_index = np.random.randint(environment_rows)\n","  current_column_index = np.random.randint(environment_columns)\n","  #continue choosing random row and column indexes until a non-terminal state is identified\n","  #(i.e., until the chosen state is a 'white square').\n","  while is_terminal_state(current_row_index, current_column_index):\n","    current_row_index = np.random.randint(environment_rows)\n","    current_column_index = np.random.randint(environment_columns)\n","  return current_row_index, current_column_index\n","\n","\n","#define an epsilon greedy algorithm that will choose which action to take next (i.e., where to move next)\n","def get_next_action(current_row_index, current_column_index, epsilon):\n","  #if a randomly chosen value between 0 and 1 is less than epsilon,\n","  #then choose the most promising value from the Q-table for this state.\n","  if np.random.random() < epsilon:\n","    return np.argmax(q_values[current_row_index, current_column_index])\n","  else: #choose a random action\n","    return np.random.randint(4)\n","\n","\n","#define a function that will get the next location based on the chosen action\n","def get_next_location(current_row_index, current_column_index, action_index):\n","  new_row_index = current_row_index\n","  new_column_index = current_column_index\n","  if actions[action_index] == 'up' and current_row_index > 0:\n","    new_row_index -= 1\n","  elif actions[action_index] == 'right' and current_column_index < environment_columns - 1:\n","    new_column_index += 1\n","  elif actions[action_index] == 'down' and current_row_index < environment_rows - 1:\n","    new_row_index += 1\n","  elif actions[action_index] == 'left' and current_column_index > 0:\n","    new_column_index -= 1\n","  return new_row_index, new_column_index\n","\n","\n","#Define a function that will get the shortest path between any location within the warehouse that\n","#the robot is allowed to travel and the item packaging location.\n","def get_shortest_path(start_row_index, start_column_index):\n","  #return immediately if this is an invalid starting location\n","  if is_terminal_state(start_row_index, start_column_index):\n","    return []\n","  else: #if this is a 'legal' starting location\n","    current_row_index, current_column_index = start_row_index, start_column_index\n","    shortest_path = []\n","    shortest_path.append([current_row_index, current_column_index])\n","    #continue moving along the path until we reach the goal (i.e., the item packaging location)\n","    while not is_terminal_state(current_row_index, current_column_index):\n","      #get the best action to take\n","      action_index = get_next_action(current_row_index, current_column_index, 1.)\n","      #move to the next location on the path, and add the new location to the list\n","      current_row_index, current_column_index = get_next_location(current_row_index, current_column_index, action_index)\n","      shortest_path.append([current_row_index, current_column_index])\n","    return shortest_path\n","\n","#define training parameters\n","epsilon = 0.9 #the percentage of time when we should take the best action (instead of a random action)\n","discount_factor = 0.9 #discount factor for future rewards\n","learning_rate = 0.9 #the rate at which the agent should learn\n","#run through 1000 training episodes\n","for episode in range(1000):\n","  #get the starting location for this episode\n","  row_index, column_index = get_starting_location()\n","  #continue taking actions (i.e., moving) until we reach a terminal state\n","  #(i.e., until we reach the item packaging area or crash into an item storage location)\n","  while not is_terminal_state(row_index, column_index):\n","    #choose which action to take (i.e., where to move next)\n","    action_index = get_next_action(row_index, column_index, epsilon)\n","    #perform the chosen action, and transition to the next state (i.e., move to the next location)\n","    old_row_index, old_column_index = row_index, column_index #store the old row and column indexes\n","    row_index, column_index = get_next_location(row_index, column_index, action_index)\n","    #receive the reward for moving to the new state, and calculate the temporal difference\n","    reward = rewards[row_index, column_index]\n","    old_q_value = q_values[old_row_index, old_column_index, action_index]\n","    temporal_difference = reward + (discount_factor * np.max(q_values[row_index, column_index])) - old_q_value\n","    #update the Q-value for the previous state and action pair\n","    new_q_value = old_q_value + (learning_rate * temporal_difference)\n","    q_values[old_row_index, old_column_index, action_index] = new_q_value\n","print('Training complete!')\n","\n","print(q_values)\n","print(get_shortest_path(0,0))\n"]},{"cell_type":"code","source":["print(get_shortest_path(0,5))"],"metadata":{"id":"Lx-1WwN25sdS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1715141411169,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shreya Shree S","userId":"02564406637729607169"}},"outputId":"e72fdc26-9465-4da2-cc07-ff04f9d13852"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oPiK-LVFXbbU"},"execution_count":null,"outputs":[]}]}